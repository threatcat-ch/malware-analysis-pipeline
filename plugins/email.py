import argparse
import datetime
import os
import json
import re
import eml_parser
import shutil
import pathlib
import time
import logging

from hashlib import new
from base64 import b64decode
from plugins.abstract_plugin import AbstractPlugin
from utils.state import State

class_name = 'Email'

class Email(AbstractPlugin):

    def __init__(self):
        super().__init__()
        self.data = {}

    # Run Email plugin
    def run(self, args):
        logging.info("Init Email Plugin")
        self.new_emails_dir = State.config['emails']['new_emails_dir']
        self.analysis_dir = State.config['emails']['analysis_dir']
        self.already_analyzed_samples = State.config['collection']['analyzed_samples']
        
        self.oldest_email_full_path = self.parse_new_email()
        logging.info(f"Email Path: {self.oldest_email_full_path}")
        if self.oldest_email_full_path:
            new_analysis_dir = self.create_analysis_dir()
            self.extract_attachments(new_analysis_dir)
            State.path = pathlib.Path(new_analysis_dir)
            with open(new_analysis_dir + 'mail.json', 'w') as f:
                json.dump(self.data, f)
            logging.info(f"New Analysis Dir: {new_analysis_dir}")

    # Extract attachments from new email    
    def extract_attachments(self, new_analysis_dir):
        ep = eml_parser.EmlParser(include_attachment_data=True)
        attachments = ep.decode_email(new_analysis_dir + 'mail.eml')
        for attachment in attachments['attachment']:
            with open(new_analysis_dir + attachment['filename'], 'wb') as f:
                f.write(b64decode(attachment['raw']))
            State.attachment_name = attachment['filename']
        return    
        
    # Create new analysis dir
    def create_analysis_dir(self):
        dir_today = datetime.datetime.now().strftime("%Y") + '/' + \
                    datetime.datetime.now().strftime("%m") + '/' + \
                    datetime.datetime.now().strftime("%d") + '/'
        if not os.path.exists(self.analysis_dir + dir_today):
            os.makedirs(self.analysis_dir + dir_today)
        list_dir_today = os.listdir(self.analysis_dir + dir_today)
        if list_dir_today:
            sorted_list_dir_today = sorted(list_dir_today, key=int)
            last_dir = sorted_list_dir_today[-1]
            new_dir = int(last_dir) + 1
            new_analysis_dir = self.analysis_dir + dir_today + str(new_dir) + '/'
            os.mkdir(new_analysis_dir)
            shutil.move(self.oldest_email_full_path, new_analysis_dir + 'mail.eml')
            return new_analysis_dir
        else:
            new_analysis_dir = self.analysis_dir + dir_today + '1' + '/'
            os.mkdir(new_analysis_dir)
            shutil.move(self.oldest_email_full_path, new_analysis_dir + 'mail.eml')
            return new_analysis_dir



    # Parse new email
    def parse_new_email(self):
        check_if_new_emails = os.listdir(self.new_emails_dir)
        if not check_if_new_emails:
            raise Exception("No email found")
        os.chdir(self.new_emails_dir)
        oldest_email = min(check_if_new_emails, key=os.path.getctime)
        oldest_email_full_path = self.new_emails_dir + oldest_email
        with open(oldest_email_full_path, 'rb') as fhdl:
            raw_email = fhdl.read()
            ep = eml_parser.EmlParser()
            parsed_eml = ep.decode_email_bytes(raw_email)
            
            # Extract email header information to use it in the MISP plugin
            # Check if there is a subject in the header
            if not parsed_eml.get('header'):
                logging.info("No header found")
                os.remove(oldest_email_full_path)
                return

            # Check if there is a subject in the header
            if parsed_eml['header'].get('subject'):
                logging.info("No subject found")
                self.data['email-subject'] = parsed_eml['header']['subject']
            if parsed_eml['header'].get('from'):
                logging.info("No from found")
                self.data['email-src-display-name'] = parsed_eml['header']['from']
            if parsed_eml['header'].get('received'):
                ipv4_regex = r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}"
                try:
                    ip_match = list(filter(lambda x: re.match(ipv4_regex, x), parsed_eml['header']['received'][-1]['from']))
                    self.data['ip-src'] = ip_match[0]
                except:
                    logging.info("No IP found")


            # Check if there is an attachment
            if parsed_eml.get('attachment'):
                logging.info(f"Attachment/s found: {parsed_eml['attachment']}")
                for filename in parsed_eml['attachment']:
                    self.data['email-attachment'] = filename['filename']
                    logging.info(f"Email Attachment Name: {filename['filename']}")
                    
                    if not os.path.isfile(self.already_analyzed_samples):
                        open(self.already_analyzed_samples, 'w')

                    with open (self.already_analyzed_samples, 'r') as collection:
                        if os.stat(self.already_analyzed_samples).st_size == 0:
                            data = []
                        else:
                            data = json.load(collection)

                        if any(d['md5'] == filename['hash']['md5'] for d in data):
                            logging.info(f"Attachment already analyzed: {filename['filename']}")
                            State.attachment_name = filename['filename']
                            os.remove(oldest_email_full_path)
                            State.progress_cause = "Already analyzed"
                            raise Exception("Already analyzed")
                            collection.close()
                            return

                        else:
                            logging.info(f"Attachment not analyzed yet: {filename['filename']}")
                            new_file_entry = {
                                                'md5': filename['hash']['md5'], 
                                                'sha1': filename['hash']['sha1'], 
                                                'sha256': filename['hash']['sha256'], 
                                                'sha512': filename['hash']['sha512']
                                                }
                            State.md5 = filename['hash']['md5']
                            State.sha256 = filename['hash']['sha256']
                            logging.info(f"{State.md5}")
                            logging.info(f"{State.sha256}")
                            data.append(new_file_entry)
                            with open(self.already_analyzed_samples, 'w') as new_collection:
                                json.dump(data, new_collection, indent=4)    
                            collection.close()
                            new_collection.close()
                            return oldest_email_full_path
            else:
                logging.info("No attachment found")
                os.remove(oldest_email_full_path)
                raise Exception("No attachments found")


